args <- commandArgs(trailingOnly = TRUE)
# the first input parameter needs to be the directory for metagenomics with all the result subdirectories
# the second input parameter needs to be the directory for metatranscriptomics with all the result subdirectories
# assumes a specific directory structure generated by default by the earlier scripts

# e.g.
# args <- character(2)
# args[1] <- "/scratch/project_2009164/2_OULANKA/Tommi/final/metagenomics"
# args[2] <- "/scratch/project_2009164/2_OULANKA/Tommi/final/metatranscriptomics"

# a small script to filter the different datas for lowly expressed features and to parse the 
# sample names and orders to match the metadata

# load libraries
library(phyloseq)
library(microbiome)

for(om in 1:length(args)){
  
  print(paste("Processing data from directory:", as.character(args[om])))
  
  # change working directory
  setwd(as.character(args[om]))
  wd <- getwd()
  
  # load and process the phyloflash taxonomy data
  setwd("phyloflash/downstream")
  
  keep_items <- ls()
  keep_items <- c(keep_items, "keep_items")
  
  load("Otu_Tax_Tables_Parsed.RData")
  # filter all datasets similarly
  # require all the used features to have at least some expression in a minimum amount of samples
  # corresponding to the smallest condition / group defined in the metadata
  # this is similar to the expression of filtering lowly expressed genes as introduced in the 
  # edgeR manual.
  
  # some expression is defined as count 5
  min_count <- 5
  
  # minimum amount of sample is defined as 6, corresponding to the amount of samples with the vegeation cluster c_cho
  min_samples <- 6
  
  # filter the NTU/OTU count tables
  
  # library sizes for phyloflash, SILVA - aligned data. Assumes that all possible rRNA in the samples have 
  # been aligned to the database and sample rRNA count sums correspond to the number of total rRNA sequences
  # and thus library sizes in the samples.
  lib_sizes <- colSums(otu_table)
  
  # make a phyloseq object - use the option where eukaryotes are summarized
  taxa <- tax_table(as.matrix(tax_table))
  otus <- otu_table(as.matrix(otu_table), taxa_are_rows = TRUE)
  samples <- sample_data(metadata)
  psq <- phyloseq(taxa, otus, samples)
  
  # reget the otu and taxonomy table from the phyloseq object to ensure correct and matching annotations
  # with other phyloseq objects downstream. Sometimes there are slight changes to rownames etc.
  otu_table <- data.frame(otu_table(psq), stringsAsFactors = F, check.names = F)
  tax_table <- data.frame(tax_table(psq), stringsAsFactors = F, check.names = F)
  
  # turn into compositional/proportional/relative data
  psq_rel <- microbiome::transform(x = psq, transform = "compositional")
  otu_table_rel <- data.frame(otu_table(psq_rel), stringsAsFactors = F, check.names = F)
  otu_table_rel <- otu_table_rel[rownames(otu_table),]
  
  # sample with the smallest library size
  loc_min_sample <- which.min(lib_sizes)
  
  # features with count 5 in the sample with the smallest library size
  locs_limit_vals <- which(otu_table[,loc_min_sample]==min_count)
  
  # require at least this much relative expression for a feature
  thres_expr <- unique(otu_table_rel[locs_limit_vals, loc_min_sample])
  
  # and in this many samples, defined earlier
  keep <- rowSums(otu_table_rel > thres_expr) >= min_samples
 
  # CLR transform before filtering as well
  psq_clr <- microbiome::transform(x = psq, transform = "clr")
  
  # extract the CLR transformed otu table
  otu_table_clr <- data.frame(otu_table(psq_clr), stringsAsFactors = F, check.names = F)
  otu_table_clr <- otu_table_clr[rownames(otu_table),]
  
  # gather the filtered datas with the lowly expressed features removed 
  otu_table_filt <- otu_table[keep,]
  otu_table_rel_filt <- otu_table_rel[keep,]
  otu_table_clr_filt <- otu_table_clr[keep,]
  tax_table_filt <- tax_table[keep,]
  
  # aggregate taxa to the desired rank level - use the same threshold
  # order
  psq_order <- aggregate_rare(psq_rel, level="Order", detection = thres_expr, prevalence = min_samples/nsamples(psq_rel))

  # phylum
  psq_phylum <- aggregate_rare(psq_rel, level="Phylum", detection = thres_expr, prevalence = min_samples/nsamples(psq_rel))
  
  # now save everything
  save(otu_table, otu_table_all, tax_table, tax_table_all, metadata, lib_sizes, min_count, min_samples, thres_expr, otu_table_rel,
       otu_table_clr, otu_table_filt, otu_table_rel_filt, otu_table_clr_filt, tax_table_filt, psq, psq_rel, psq_clr, psq_order, psq_phylum, file = "Otu_Tax_Tables_Parsed_Filtered.RData")
  
  # clean workspace
  keep_items <- c(keep_items, "metadata")
  del_items <- ls()
  del_items <- del_items[-which(del_items%in%keep_items)]
  rm(list = del_items)
  
  # load and process the KEGG KO data
  setwd(wd)
  setwd("kegg_diamond")
  load("All_The_Output_Matrices_For_Downstream.RData")
  
  # parse sample names and order to match metadata
  colnames(ko_samples_tpm) <- paste("P",unlist(lapply(colnames(ko_samples_tpm), function(x) strsplit(x = x, split = "-")[[1]][1])), sep = "")
  ko_samples_tpm <- ko_samples_tpm[,rownames(metadata)]
  
  colnames(ko_samples_count) <- paste("P",unlist(lapply(colnames(ko_samples_count), function(x) strsplit(x = x, split = "-")[[1]][1])), sep = "")
  ko_samples_count <- ko_samples_count[,rownames(metadata)]
  
  colnames(ko_samples_rpm) <- paste("P",unlist(lapply(colnames(ko_samples_rpm), function(x) strsplit(x = x, split = "-")[[1]][1])), sep = "")
  ko_samples_rpm <- ko_samples_rpm[,rownames(metadata)]
  
  names(rpk_scaling_factors) <- paste("P",unlist(lapply(names(rpk_scaling_factors), function(x) strsplit(x = x, split = "-")[[1]][1])), sep = "")
  rpk_scaling_factors <- rpk_scaling_factors[rownames(metadata)]
  
  names(count_scaling_factors) <- paste("P",unlist(lapply(names(count_scaling_factors), function(x) strsplit(x = x, split = "-")[[1]][1])), sep = "")
  count_scaling_factors <- count_scaling_factors[rownames(metadata)]
  
  # filter the datasets similarly to the taxonomic data
  # require all the used features to have at least some expression in a minimum amount of samples
  # corresponding to the smallest condition / group defined in the metadata
  # this is similar to the expression of filtering lowly expressed genes as introduced in the 
  # edgeR manual.
  
  # some expression is defined as count 5
  min_count <- 5
  
  # minimum amount of sample is defined as 6, corresponding to the amount of samples with the vegeation cluster c_cho
  min_samples <- 6
  
  # filter tpm data and rpm data based on rpm thres
  loc_min_sample <- which.min(count_scaling_factors)
  locs_limit_vals <- which(ko_samples_count[,loc_min_sample]==min_count)
  
  # use the rpm data for filtering, where the counts for features have been adjusted to the library size
  thres_expr <- unique(ko_samples_rpm[locs_limit_vals, loc_min_sample])
  keep <- rowSums(ko_samples_rpm > thres_expr ) >= min_samples
  
  ko_tpm_data <- ko_samples_tpm[keep,]
  ko_rpm_data <- ko_samples_rpm[keep,]
  ko_count_data <- ko_samples_count[keep,]

  # save everything
  save(ko_tpm_data, ko_rpm_data, ko_count_data, ko_samples_tpm, ko_samples_rpm, ko_samples_rpk, ko_samples_count, all_sample_info, count_scaling_factors, rpk_scaling_factors, rpk_cor_factors,
       metadata, min_count, min_samples, thres_expr, file = "Matrices_For_Downstream.RData")

    # clean workspace
  del_items <- ls()
  del_items <- del_items[-which(del_items%in%keep_items)]
  rm(list = del_items)
  
  # load and process the metabolic marker gene data
  setwd(wd)
  setwd("metmarkdb_diamond")
  load("All_The_Output_Matrices_For_Downstream.RData")
  
  # parse sample names and order to match metadata
  colnames(hits_samples_tpm) <- paste("P",unlist(lapply(colnames(hits_samples_tpm), function(x) strsplit(x = x, split = "-")[[1]][1])), sep = "")
  hits_samples_tpm <- hits_samples_tpm[,rownames(metadata)]
  
  colnames(hits_samples_count) <- paste("P",unlist(lapply(colnames(hits_samples_count), function(x) strsplit(x = x, split = "-")[[1]][1])), sep = "")
  hits_samples_count <- hits_samples_count[,rownames(metadata)]
  
  colnames(hits_samples_rpm) <- paste("P",unlist(lapply(colnames(hits_samples_rpm), function(x) strsplit(x = x, split = "-")[[1]][1])), sep = "")
  hits_samples_rpm <- hits_samples_rpm[,rownames(metadata)]
  
  names(rpk_scaling_factors) <- paste("P",unlist(lapply(names(rpk_scaling_factors), function(x) strsplit(x = x, split = "-")[[1]][1])), sep = "")
  rpk_scaling_factors <- rpk_scaling_factors[rownames(metadata)]
  
  names(count_scaling_factors) <- paste("P",unlist(lapply(names(count_scaling_factors), function(x) strsplit(x = x, split = "-")[[1]][1])), sep = "")
  count_scaling_factors <- count_scaling_factors[rownames(metadata)]
  
  # filter similarly to the phyloflasj and KEGG data
  
  # some expression is defined as count 5
  min_count <- 5
  
  # minimum amount of sample is defined as 6, corresponding to the amount of samples with the vegeation cluster c_cho
  min_samples <- 6
  
  # filter tpm data and rpm data based on rpm thres
  loc_min_sample <- which.min(count_scaling_factors)
  locs_limit_vals <- which(hits_samples_count[,loc_min_sample]==min_count)
  
  # use the rpm data for filtering, where the counts for features have been adjuted to the library size
  thres_expr <- unique(hits_samples_rpm[locs_limit_vals, loc_min_sample])
  keep <- rowSums(hits_samples_rpm > thres_expr ) >= min_samples
  
  metmark_tpm_data <- hits_samples_tpm[keep,]
  metmark_rpm_data <- hits_samples_rpm[keep,]
  metmark_count_data <- hits_samples_count[keep,]
  
  # save everything
  save(metmark_tpm_data, metmark_rpm_data, metmark_count_data, hits_samples_tpm, hits_samples_rpm, hits_samples_rpk, hits_samples_count, all_sample_info, count_scaling_factors, rpk_scaling_factors,
       metadata, min_count, min_samples, thres_expr, file = "Matrices_For_Downstream.RData")
  
}

# print out session info
print("SessionInfo:")
sessionInfo()